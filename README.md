# ğŸ“¡ Radar de Editais & Fomento

Ferramenta de **Engenharia de Dados** que monitora automaticamente portais do governo em busca de oportunidades de fomento, bolsas e editais culturais/cientÃ­ficos.

O sistema realiza o ciclo completo de **ETL (Extract, Transform, Load)**: extrai dados de mÃºltiplos sites, aplica filtros de limpeza e temporalidade, consolida em um banco histÃ³rico e exibe em um dashboard interativo.

## ğŸš€ Funcionalidades

- **Coleta Multi-Site:** Varredura automÃ¡tica no **CNPq**, **IPHAN** e **IBRAM**.
- **Filtro Inteligente:**
  - **Blacklist Institucional:** Remove links irrelevantes ("Quem somos", "Estatuto").
  - **Filtro Temporal:** Ignora editais antigos/encerrados, focando em 2025/2026.
  - **DeduplicaÃ§Ã£o:** Garante que apenas novas oportunidades sejam adicionadas ao banco.
- **PersistÃªncia de Dados:** HistÃ³rico salvo incrementalmente em CSV.
- **Dashboard Interativo:** Interface visual em **Streamlit** para busca e filtragem.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.10+**
- **Web Scraping:** `Requests`, `BeautifulSoup4`
- **ManipulaÃ§Ã£o de Dados:** `Pandas`
- **VisualizaÃ§Ã£o:** `Streamlit`

## âš™ï¸ Como Rodar Localmente

1. **Clone o repositÃ³rio:**

    git clone https://github.com/SEU_USUARIO/agregador-editais.git
    cd agregador-editais

2. **Instale as dependÃªncias:**

    pip install -r requirements.txt

3. **Execute o RobÃ´ de Coleta (ETL):**
   Este script vai varrer a internet e atualizar o arquivo CSV.

    python coletor.py

4. **Abra o Dashboard:**
   Para visualizar e filtrar os dados coletados.

    streamlit run dashboard.py

## ğŸ“‚ Estrutura do Projeto

- `coletor.py`: O "cÃ©rebro" do robÃ´. ContÃ©m a lÃ³gica de extraÃ§Ã£o, limpeza (blacklist/whitelist) e salvamento incremental.
- `dashboard.py`: A interface grÃ¡fica. LÃª o CSV gerado e cria a visualizaÃ§Ã£o web.
- `oportunidades_consolidada.csv`: Banco de dados local (gerado apÃ³s a primeira execuÃ§Ã£o).

## ğŸ“ LicenÃ§a

Desenvolvido para fins educacionais e de portfÃ³lio.